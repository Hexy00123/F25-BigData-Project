{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0582225-d398-4796-ac26-058c4f723dd1",
   "metadata": {},
   "source": [
    "# Phase 3 | ML modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6823acd-1f70-4a61-bbf7-deb89c15c0af",
   "metadata": {},
   "source": [
    "## 1. Reading dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5770e549-de33-47de-be4f-f320cf3a1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "team = 'team11'\n",
    "\n",
    "warehouse = \"/user/team11/project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7bd55c-caa3-4269-9044-d5a888537a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             retake1|\n",
      "|             root_db|\n",
      "|                show|\n",
      "|     team0_projectdb|\n",
      "|    team11_projectdb|\n",
      "|           team12_db|\n",
      "|team12_hive_proje...|\n",
      "|    team12_projectdb|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team17_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "| team21_projectdb_v2|\n",
      "| team21_projectdb_v3|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435b6602-087d-4e42-9f3a-f9e538240f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+----------------+---------------+-----------+\n",
      "|       namespace|      tableName|isTemporary|\n",
      "+----------------+---------------+-----------+\n",
      "|team11_projectdb|     q1_results|      false|\n",
      "|team11_projectdb|     q2_results|      false|\n",
      "|team11_projectdb|     q3_results|      false|\n",
      "|team11_projectdb|     q4_results|      false|\n",
      "|team11_projectdb|     q5_results|      false|\n",
      "|team11_projectdb|     q6_results|      false|\n",
      "|team11_projectdb|     q7_results|      false|\n",
      "|team11_projectdb|     taxi_trips|      false|\n",
      "|team11_projectdb|taxi_trips_part|      false|\n",
      "+----------------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE team11_projectdb\").show()\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddd18f99-8cd6-43dd-a0e7-49c573334518",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips = spark.read.format(\"avro\").table('team11_projectdb.taxi_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4112fba2-25a4-4f8e-9e3b-76bf6f7f8abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|   pickup_latitude|ratecodeid|store_and_fwd_flag| dropoff_longitude|  dropoff_latitude|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+\n",
      "|       1|       1456779600000|        1456780075000|              1|          2.5|-73.97674560546875| 40.76515197753906|         1|                 N|-74.00426483154297| 40.74612808227539|        9.0|  0.5|    0.5|      2.05|         0.0|                  0.3|       12.35|           1|\n",
      "|       1|       1456779600000|        1456780266000|              1|          2.9|-73.98348236083984| 40.76792526245117|         1|                 N|-74.00594329833984|  40.7331657409668|       11.0|  0.5|    0.5|      3.05|         0.0|                  0.3|       15.35|           1|\n",
      "|       2|       1456779600000|        1456781466000|              2|        19.98|-73.78202056884766| 40.64480972290039|         1|                 N|-73.97454071044922|  40.6757698059082|       54.5|  0.5|    0.5|       8.0|         0.0|                  0.3|        63.8|           1|\n",
      "|       2|       1456779600000|        1456779600000|              3|        10.78|-73.86341857910156|40.769813537597656|         1|                 N|-73.96965026855469| 40.75776672363281|       31.5|  0.0|    0.5|      3.78|        5.54|                  0.3|       41.62|           1|\n",
      "|       2|       1456779600000|        1456779600000|              5|        30.43|-73.97174072265625| 40.79218292236328|         3|                 N|-74.17716979980469| 40.69505310058594|       98.0|  0.0|    0.0|       0.0|        15.5|                  0.3|       113.8|           1|\n",
      "|       2|       1456779600000|        1456779600000|              5|         5.92|-74.01719665527344| 40.70538330078125|         1|                 N|-73.97807312011719| 40.75578689575195|       23.5|  1.0|    0.5|      5.06|         0.0|                  0.3|       30.36|           1|\n",
      "|       2|       1456779600000|        1456779600000|              6|         5.72|-73.99458312988281|40.727848052978516|         1|                 N|               0.0|               0.0|       23.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        24.3|           2|\n",
      "|       1|       1456779601000|        1456780564000|              1|          6.2|-73.78877258300781| 40.64775848388672|         1|                 N|-73.82920837402344|40.712345123291016|       20.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        21.8|           3|\n",
      "|       1|       1456779601000|        1456779900000|              1|          0.7|-73.95822143554688| 40.76464080810547|         1|                 N| -73.9678955078125|40.762901306152344|        5.5|  0.5|    0.5|       2.0|         0.0|                  0.3|         8.8|           1|\n",
      "|       2|       1456779601000|        1456781046000|              3|         7.18|-73.98577880859375| 40.74119186401367|         1|                 N|-73.94635009765625| 40.79787826538086|       23.5|  0.5|    0.5|       3.2|         0.0|                  0.3|        28.0|           1|\n",
      "|       2|       1456779601000|        1456779723000|              2|         0.54| -73.9884262084961|    40.76416015625|         1|                 N|-73.99239349365234| 40.75822448730469|        4.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.3|           2|\n",
      "|       1|       1456779602000|        1456780069000|              1|          1.7|-73.96981811523438|40.797428131103516|         1|                 N|-73.94377136230469|40.796199798583984|        8.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.3|           2|\n",
      "|       1|       1456779602000|        1456779785000|              1|          1.1|-73.95380401611328| 40.78812789916992|         1|                 N|-73.97154998779297| 40.79523849487305|        5.5|  0.5|    0.5|       2.2|         0.0|                  0.3|         9.0|           1|\n",
      "|       2|       1456779602000|        1456780172000|              1|          2.1|-73.97608947753906| 40.75217056274414|         1|                 N| -73.9874496459961|40.770782470703125|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|           1|\n",
      "|       2|       1456779602000|        1456781051000|              1|         8.54|-74.00206756591797|40.719120025634766|         1|                 N|-73.95211791992188|40.811241149902344|       27.0|  0.5|    0.5|      5.66|         0.0|                  0.3|       33.96|           1|\n",
      "|       2|       1456779602000|        1456780104000|              1|          2.0|-74.00672912597656|40.730716705322266|         1|                 N|-74.01704406738281| 40.70936584472656|        8.5|  0.5|    0.5|       2.0|         0.0|                  0.3|        11.8|           1|\n",
      "|       1|       1456779603000|        1456780163000|              1|          3.2| -74.0066146850586| 40.71662139892578|         1|                 N|-73.99010467529297| 40.75605010986328|       11.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|           2|\n",
      "|       2|       1456779603000|        1456780114000|              1|         1.59|-73.98226928710938|  40.7706184387207|         1|                 N|-73.96874237060547| 40.75503921508789|        8.0|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|           1|\n",
      "|       2|       1456779603000|        1456781565000|              3|        16.81|-73.79238891601562|  40.6450309753418|         2|                 N|-73.98628997802734| 40.75851821899414|       52.0|  0.0|    0.5|       8.0|        5.54|                  0.3|       66.34|           1|\n",
      "|       1|       1456779604000|        1456779810000|              2|          0.5| -73.9837875366211| 40.73189163208008|         1|                 N|-73.97581481933594|40.728519439697266|        4.5|  0.5|    0.5|      1.15|         0.0|                  0.3|        6.95|           1|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870708b7-d6b8-46e1-926a-9d0214e3e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendorid: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- ratecodeid: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ce3d9-a307-42d4-ac9f-cd3e34b0d6de",
   "metadata": {},
   "source": [
    "## 2. Feature extraction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b607daa8-f48a-45a2-9802-f6195e9ec37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler,\n",
    "    SQLTransformer,\n",
    "    StandardScaler\n",
    ")\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col, count, when, hour, month, sin, cos, to_timestamp, from_unixtime, lit\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be678629-b393-47ff-bfa2-56f3ebce3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnixMillisToTimestamp(Transformer):\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(UnixMillisToTimestamp, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        return dataset.withColumn(\n",
    "            self.outputCol,\n",
    "            to_timestamp(from_unixtime(col(self.inputCol)/1000))\n",
    "        )\n",
    "\n",
    "# Custom Transformer to extract hour and month\n",
    "class ExtractHourMonth(Transformer):\n",
    "    def __init__(self, inputCol=None, prefix=\"pickup\"):\n",
    "        super(ExtractHourMonth, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset.withColumn(f\"{self.prefix}_hour\", hour(col(self.inputCol)))\n",
    "        return dataset.withColumn(f\"{self.prefix}_month\", month(col(self.inputCol)))\n",
    "\n",
    "\n",
    "# Custom Transformer for cyclical encoding\n",
    "class CyclicalEncoder(Transformer):\n",
    "    def __init__(self):\n",
    "        super(CyclicalEncoder, self).__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset.withColumn(\"pickup_hour_sin\", sin(2 * math.pi * col(\"pickup_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"pickup_hour_cos\", cos(2 * math.pi * col(\"pickup_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"pickup_month_sin\", sin(2 * math.pi * col(\"pickup_month\") / lit(12)))\n",
    "        dataset = dataset.withColumn(\"pickup_month_cos\", cos(2 * math.pi * col(\"pickup_month\") / lit(12)))\n",
    "        dataset = dataset.withColumn(\"dropoff_hour_sin\", sin(2 * math.pi * col(\"dropoff_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"dropoff_hour_cos\", cos(2 * math.pi * col(\"dropoff_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"dropoff_month_sin\", sin(2 * math.pi * col(\"dropoff_month\") / lit(12)))\n",
    "        return dataset.withColumn(\"dropoff_month_cos\", cos(2 * math.pi * col(\"dropoff_month\") / lit(12)))\n",
    "\n",
    "\n",
    "# Custom Transformer to select features and rename label\n",
    "class SelectAndRename(Transformer):\n",
    "    def _transform(self, dataset):\n",
    "        cols = [\n",
    "            'total_amount', 'vendorid',\n",
    "            'passenger_count', 'trip_distance',\n",
    "            'pickup_longitude', 'pickup_latitude',\n",
    "            'dropoff_longitude', 'dropoff_latitude',\n",
    "            'pickup_hour_sin', 'pickup_hour_cos',\n",
    "            'pickup_month_sin', 'pickup_month_cos',\n",
    "            'dropoff_hour_sin', 'dropoff_hour_cos',\n",
    "            'dropoff_month_sin', 'dropoff_month_cos'\n",
    "        ]\n",
    "        dataset = dataset.select(*cols)\n",
    "        return dataset.withColumnRenamed(\"total_amount\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "91c4592e-bec6-4856-8748-3023a535bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = spark.read.format(\"avro\").table('team11_projectdb.taxi_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0aca2631-6a1f-448e-8a55-154f8bb95d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+-------+---------+\n",
      "|        mean_amt|          std_amt|min_amt|  max_amt|\n",
      "+----------------+-----------------+-------+---------+\n",
      "|16.0458196739506|134.3577728869812| -376.3|429562.25|\n",
      "+----------------+-----------------+-------+---------+\n",
      "\n",
      "Total_amount quantiles (50%,75%,90%,95%,99%): [6.8, 7.88, 11.8, 17.76, 28.3, 45.38, 429562.25]\n"
     ]
    }
   ],
   "source": [
    "df_all.selectExpr(\n",
    "    \"mean(total_amount) as mean_amt\",\n",
    "    \"stddev(total_amount) as std_amt\",\n",
    "    \"min(total_amount) as min_amt\",\n",
    "    \"max(total_amount) as max_amt\"\n",
    ").show()\n",
    "\n",
    "total_amount_quantiles = df_all.stat.approxQuantile(\"total_amount\", [0.1, 0.2, 0.5, 0.75, 0.9, 0.95, 0.99], 0.01)\n",
    "print(\"Total_amount quantiles (50%,75%,90%,95%,99%):\", total_amount_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7fe72fe3-2ca6-42cb-b113-e74789fe3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.filter(col(\"total_amount\") >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "400c1b59-d6e9-47f9-badc-326a87b26355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered quantiles: 0.0 429562.25\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Recompute quantiles on cleaned data\n",
    "q1, q99 = df_all.stat.approxQuantile(\"total_amount\", [0.01, 0.99], 0.01)\n",
    "print(\"Filtered quantiles:\", q1, q99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ca4e52eb-17ba-48e6-80aa-f6847eda5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|total_amount|\n",
      "+------------+\n",
      "|429562.25   |\n",
      "|133131.2    |\n",
      "|126366.58   |\n",
      "|2009.34     |\n",
      "|1463.12     |\n",
      "|1426.8      |\n",
      "|1347.39     |\n",
      "|1273.3      |\n",
      "|1247.3      |\n",
      "|1121.3      |\n",
      "|1000.8      |\n",
      "|989.8       |\n",
      "|983.3       |\n",
      "|981.82      |\n",
      "|934.37      |\n",
      "|902.8       |\n",
      "|901.1       |\n",
      "|900.3       |\n",
      "|892.8       |\n",
      "|852.9       |\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.orderBy(col(\"total_amount\").desc()).select(\"total_amount\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cf60b99c-93a8-4953-a5ba-305d5173a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter out outliers outside the 1st and 99th percentiles\n",
    "df_all = df_all.filter(col(\"total_amount\") < 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8b9e1c87-7c06-407e-9496-76c399741c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_frac = 0.5\n",
    "# df_sample = df_all.sample(False, sample_frac, seed=42)\n",
    "# train_df, test_df = df_sample.randomSplit([0.2, 0.8], seed=42)\n",
    "# train_df, test_df, _ = df_sample.randomSplit([0.08, 0.2, 0.72], seed=42)\n",
    "\n",
    "# 3. Build preprocessing pipeline with custom transformers\n",
    "preprocessing = Pipeline(stages=[\n",
    "    UnixMillisToTimestamp(inputCol=\"tpep_pickup_datetime\", outputCol=\"pickup_ts\"),\n",
    "    UnixMillisToTimestamp(inputCol=\"tpep_dropoff_datetime\", outputCol=\"dropoff_ts\"),\n",
    "    ExtractHourMonth(inputCol=\"pickup_ts\", prefix=\"pickup\"),\n",
    "    ExtractHourMonth(inputCol=\"dropoff_ts\", prefix=\"dropoff\"),\n",
    "    CyclicalEncoder(),\n",
    "    SelectAndRename(),\n",
    "    VectorAssembler(\n",
    "        inputCols=[\n",
    "            'vendorid',\n",
    "            'passenger_count', 'trip_distance',\n",
    "            'pickup_longitude', 'pickup_latitude',\n",
    "            'dropoff_longitude', 'dropoff_latitude',\n",
    "            'pickup_hour_sin', 'pickup_hour_cos',\n",
    "            'pickup_month_sin', 'pickup_month_cos',\n",
    "            'dropoff_hour_sin', 'dropoff_hour_cos',\n",
    "            'dropoff_month_sin', 'dropoff_month_cos'\n",
    "        ], outputCol='features_raw'\n",
    "    ),\n",
    "    StandardScaler(inputCol='features_raw',\n",
    "                   outputCol='features',\n",
    "                   withMean=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0035f-da8c-4afb-b5fa-b89d8ec4465d",
   "metadata": {},
   "source": [
    "## 3. Splitting dataset into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f0b7a7fc-e7b4-4dd6-8858-93690774fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frac = 0.2\n",
    "df_sample = df_all.sample(False, sample_frac, seed=42)\n",
    "\n",
    "train_df, test_df = df_sample.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5bc111a2-03aa-4603-a216-870a28dce456",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = preprocessing.fit(train_df)\n",
    "train = temp_model.transform(train_df)\n",
    "test = temp_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8b91cb41-393b-49cf-8d82-325ad6f6e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "train.select(\"features\", \"label\").coalesce(1)\\\n",
    "    .write.mode(\"overwrite\").json(\"project/data/train\")\n",
    "test.select(\"features\", \"label\").coalesce(1)\\\n",
    "    .write.mode(\"overwrite\").json(\"project/data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2473b-2af2-46c1-8934-faa0b7f71207",
   "metadata": {},
   "source": [
    "## 4. Initial testing of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "027734c2-7fbe-4e28-b71a-cef7e4b6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",\n",
    "                           labelCol=\"label\")\n",
    "model_rf = rf.fit(train)\n",
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4de7183c-589b-4178-9bab-7e00f234f461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Results for RandomForestRegressor ===\n",
      "Training time: 875.67 seconds\n",
      "Training time: 404.70 seconds\n",
      "RMSE: 6.4111\n",
      "R^2: 0.7762\n",
      "MSE: 41.1022\n",
      "MAE: 3.2362\n"
     ]
    }
   ],
   "source": [
    "start_time_test = time.time()\n",
    "predictions = model_rf.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "mse = evaluator.setMetricName(\"mse\").evaluate(predictions)\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "time_test = time.time() - start_time_test\n",
    "\n",
    "print(\"=== Evaluation Results for RandomForestRegressor ===\")\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "print(f\"Evaluation time: {time_test:.2f} seconds\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "87fb3770-d7ba-43e8-8b14-88534f2284b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|prediction        |label|\n",
      "+------------------+-----+\n",
      "|10.568660757935772|8.8  |\n",
      "|16.873684916522244|12.3 |\n",
      "|10.568660757935772|6.8  |\n",
      "|11.790531520268951|12.35|\n",
      "|15.791738926528643|17.15|\n",
      "|18.193336422116538|18.8 |\n",
      "|32.08915779379674 |28.55|\n",
      "|10.666776288458921|7.3  |\n",
      "|16.649204976568754|17.9 |\n",
      "|10.666776288458921|7.3  |\n",
      "|12.47722301163988 |10.3 |\n",
      "|14.296030140696493|16.56|\n",
      "|13.828616441429634|15.37|\n",
      "|32.16429897045403 |39.3 |\n",
      "|10.564096434894076|7.55 |\n",
      "|10.568660757935772|6.95 |\n",
      "|15.80866510158971 |17.9 |\n",
      "|11.609280325959745|11.75|\n",
      "|34.59368646781287 |34.55|\n",
      "|16.516848598486806|14.15|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\") \\\n",
    "    .limit(20) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "99916a9c-5468-4d29-8a3c-4de0cb4e8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rf = GBTRegressor(featuresCol=\"features\",\n",
    "                  labelCol=\"label\",\n",
    "                  maxDepth=3)\n",
    "model_rf = rf.fit(train)\n",
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e21d18f0-edc9-469a-9912-38387e34a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Results for GBTRegressor ===\n",
      "Training time: 773.59 seconds\n",
      "Training time: 66.05 seconds\n",
      "RMSE: 5.8052\n",
      "R^2: 0.8165\n",
      "MSE: 33.7002\n",
      "MAE: 2.4922\n"
     ]
    }
   ],
   "source": [
    "start_time_test = time.time()\n",
    "predictions = model_rf.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "mse = evaluator.setMetricName(\"mse\").evaluate(predictions)\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "time_test = time.time() - start_time_test\n",
    "\n",
    "print(\"=== Evaluation Results for GBTRegressor ===\")\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "print(f\"Evaluation time: {time_test:.2f} seconds\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "865ac1f7-4147-4240-bc1e-e1d0d827cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|prediction        |label|\n",
      "+------------------+-----+\n",
      "|8.01600119207089  |5.3  |\n",
      "|9.43524358732633  |8.3  |\n",
      "|9.661914705262852 |13.55|\n",
      "|7.416017635011658 |6.3  |\n",
      "|11.458635224998725|9.3  |\n",
      "|12.083137659017128|10.3 |\n",
      "|8.001372660109379 |3.8  |\n",
      "|8.030401030977027 |7.5  |\n",
      "|12.351925774410056|15.35|\n",
      "|22.83962424833976 |14.8 |\n",
      "|12.05258235522442 |9.8  |\n",
      "|26.104474077649797|25.07|\n",
      "|42.93618542654207 |47.89|\n",
      "|7.8229376868268545|7.3  |\n",
      "|16.607330704517665|13.3 |\n",
      "|15.88247029146832 |26.3 |\n",
      "|22.69089189797387 |20.15|\n",
      "|12.202018961535726|11.8 |\n",
      "|8.605391741157387 |5.3  |\n",
      "|16.748618136966   |16.8 |\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\") \\\n",
    "    .limit(50) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694a371-1ff2-4a6f-8c0a-0e2ba0de25d3",
   "metadata": {},
   "source": [
    "## 5. Full training pipeline: baseline models + grid search + saving results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "73c8cf46-3e84-4217-b279-e94fd5c3034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8a9bc174-e945-4a60-ad08-bedb2f0f0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = [\n",
    "    {\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"estimator\": RandomForestRegressor(featuresCol=\"features\",\n",
    "                                           labelCol=\"label\"),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GBT\",\n",
    "        \"estimator\": GBTRegressor(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "# Build parameter grids referring to the same estimator instances:\n",
    "models_config[0][\"param_grid\"] = ParamGridBuilder()  \\\n",
    "    .addGrid(models_config[0][\"estimator\"].numTrees, [10, 40])  \\\n",
    "    .addGrid(models_config[0][\"estimator\"].maxDepth, [5, 10])  \\\n",
    "    .build()\n",
    "\n",
    "models_config[1][\"param_grid\"] = ParamGridBuilder()  \\\n",
    "    .addGrid(models_config[1][\"estimator\"].maxDepth, [3, 8])  \\\n",
    "    .addGrid(models_config[1][\"estimator\"].maxBins, [24, 32])  \\\n",
    "    .build()\n",
    "\n",
    "# Add output paths\n",
    "models_config[0].update({\"output_model\": \"model1\",\n",
    "                         \"output_pred\": \"model1_predictions\"})\n",
    "models_config[1].update({\"output_model\": \"model2\",\n",
    "                         \"output_pred\": \"model2_predictions\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a5baf-4230-4c11-a290-7ad5863d0ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running baseline model for: RandomForest ===\n",
      "Baseline training time: 67.48 seconds\n",
      "Baseline RMSE: 6.5116, R²: 0.7722\n",
      "Baseline test time: 11.71 seconds\n",
      "\n",
      "--- Running hyperparameter tuning for: RandomForest ---\n",
      "[{Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
      " {Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
      " {Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 40},\n",
      " {Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 40}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in models_config:\n",
    "    print(f\"\\n=== Running baseline model for: {config['name']} ===\")\n",
    "\n",
    "    # Step 1: Train baseline model (no tuning)\n",
    "    base_estimator = config[\"estimator\"]\n",
    "    baseline_start = time.time()\n",
    "    baseline_model = base_estimator.fit(train)\n",
    "    baseline_train_time = time.time() - baseline_start\n",
    "    print(f\"Baseline training time: {baseline_train_time:.2f} seconds\")\n",
    "\n",
    "    baseline_start_test = time.time()\n",
    "    baseline_predictions = baseline_model.transform(test)\n",
    "    baseline_rmse = evaluator.setMetricName(\"rmse\")\\\n",
    "        .evaluate(baseline_predictions)\n",
    "    baseline_r2 = evaluator.setMetricName(\"r2\")\\\n",
    "        .evaluate(baseline_predictions)\n",
    "    baseline_test_time = time.time() - baseline_start_test\n",
    "    print(f\"Baseline RMSE: {baseline_rmse:.4f}, R²: {baseline_r2:.4f}\")\n",
    "    print(f\"Baseline test time: {baseline_test_time:.2f} seconds\")\n",
    "\n",
    "    results.append((\n",
    "        f\"{config['name']}_baseline\",\n",
    "        \"{}\",\n",
    "        baseline_rmse,\n",
    "        baseline_r2,\n",
    "        baseline_train_time,\n",
    "        baseline_test_time\n",
    "    ))\n",
    "\n",
    "    # Save baseline model and predictions\n",
    "    baseline_model.write().overwrite()\\\n",
    "        .save(f\"project/models/{config['output_model']}_baseline\")\n",
    "    baseline_predictions.select(\"label\", \"prediction\") \\\n",
    "        .coalesce(1) \\\n",
    "        .write.mode(\"overwrite\")\\\n",
    "        .csv(f\"project/output/{config['output_pred']}_baseline\", header=True)\n",
    "\n",
    "    # Step 2: Hyperparameter tuning with CrossValidator\n",
    "    print(f\"\\n--- Running hyperparameter tuning for: {config['name']} ---\")\n",
    "    pprint(config[\"param_grid\"])\n",
    "    tuning_start = time.time()\n",
    "\n",
    "    cv = CrossValidator(\n",
    "        estimator=config[\"estimator\"],\n",
    "        estimatorParamMaps=config[\"param_grid\"],\n",
    "        evaluator=evaluator.setMetricName(\"rmse\"),\n",
    "        numFolds=3,\n",
    "        parallelism=4\n",
    "    )\n",
    "    tuned_model = cv.fit(train).bestModel\n",
    "    tuning_train_time = time.time() - tuning_start\n",
    "    print(f\"Tuning completed in {tuning_train_time:.2f} seconds\")\n",
    "\n",
    "    param_map = tuned_model.extractParamMap()\n",
    "    params = {p.name: tuned_model.getOrDefault(p) for p in param_map.keys()}\n",
    "    grid_params = config['param_grid'][0].keys()\n",
    "    relevant_param_names = [gp.name for gp in grid_params]\n",
    "    filtered_params = {k: v for k, v in params.items() if k in relevant_param_names}\n",
    "\n",
    "    # Save tuned model and predictions\n",
    "    tuned_model.write().overwrite()\\\n",
    "        .save(f\"project/models/{config['output_model']}\")\n",
    "    tuning_start_test = time.time()\n",
    "    tuned_predictions = tuned_model.transform(test)\n",
    "    tuned_predictions.select('label', 'prediction') \\\n",
    "        .coalesce(1) \\\n",
    "        .write.mode('overwrite')\\\n",
    "        .csv(f\"project/output/{config['output_pred']}\", header=True)\n",
    "\n",
    "    tuned_rmse = evaluator.setMetricName(\"rmse\").evaluate(tuned_predictions)\n",
    "    tuned_r2 = evaluator.setMetricName(\"r2\").evaluate(tuned_predictions)\n",
    "    print(f\"Tuned RMSE: {tuned_rmse:.4f}, R²: {tuned_r2:.4f}\")\n",
    "    tuning_test_time = time.time() - tuning_start_test\n",
    "    print(f\"Baseline test time: {tuning_test_time:.2f} seconds\")\n",
    "\n",
    "    results.append((\n",
    "        f\"{config['name']}_tuned\",\n",
    "        str(filtered_params),\n",
    "        tuned_rmse,\n",
    "        tuned_r2,\n",
    "        tuning_train_time,\n",
    "        tuning_test_time))\n",
    "# Final summary\n",
    "summary = spark.createDataFrame(results, [\"model\", \"params\", \"rmse\", \"r2\", \"train_time_sec\", \"eval_time_sec\"])\n",
    "summary.show(truncate=False)\n",
    "summary.coalesce(1) \\\n",
    "    .write.mode('overwrite').csv(\"project/output/evaluation\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c035a81a-d315-42c2-954c-27f97a2e4b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'maxDepth': 10, 'numTrees': 40}\n"
     ]
    }
   ],
   "source": [
    "print(filtered_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
