{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0582225-d398-4796-ac26-058c4f723dd1",
   "metadata": {},
   "source": [
    "# Phase 3 | ML modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6823acd-1f70-4a61-bbf7-deb89c15c0af",
   "metadata": {},
   "source": [
    "## 1. Reading dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5770e549-de33-47de-be4f-f320cf3a1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "team = 'team11'\n",
    "\n",
    "warehouse = \"/user/team11/project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7bd55c-caa3-4269-9044-d5a888537a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             retake1|\n",
      "|             root_db|\n",
      "|                show|\n",
      "|     team0_projectdb|\n",
      "|    team11_projectdb|\n",
      "|           team12_db|\n",
      "|team12_hive_proje...|\n",
      "|    team12_projectdb|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "| team21_projectdb_v2|\n",
      "| team21_projectdb_v3|\n",
      "| team21_projectdb_v4|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435b6602-087d-4e42-9f3a-f9e538240f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+----------------+---------------+-----------+\n",
      "|       namespace|      tableName|isTemporary|\n",
      "+----------------+---------------+-----------+\n",
      "|team11_projectdb|    mq1_results|      false|\n",
      "|team11_projectdb|    mq_features|      false|\n",
      "|team11_projectdb|mq_features_raw|      false|\n",
      "|team11_projectdb|     mq_model_1|      false|\n",
      "|team11_projectdb|     mq_model_2|      false|\n",
      "|team11_projectdb|     q1_results|      false|\n",
      "|team11_projectdb|     q2_results|      false|\n",
      "|team11_projectdb|     q3_results|      false|\n",
      "|team11_projectdb|     q4_results|      false|\n",
      "|team11_projectdb|     q5_results|      false|\n",
      "|team11_projectdb|     q6_results|      false|\n",
      "|team11_projectdb|     q7_results|      false|\n",
      "|team11_projectdb|     taxi_trips|      false|\n",
      "|team11_projectdb|taxi_trips_part|      false|\n",
      "+----------------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE team11_projectdb\").show()\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd18f99-8cd6-43dd-a0e7-49c573334518",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_trips = spark.read.format(\"avro\").table('team11_projectdb.taxi_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4112fba2-25a4-4f8e-9e3b-76bf6f7f8abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|   pickup_latitude|ratecodeid|store_and_fwd_flag| dropoff_longitude|  dropoff_latitude|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+\n",
      "|       1|       1456779600000|        1456780075000|              1|          2.5|-73.97674560546875| 40.76515197753906|         1|                 N|-74.00426483154297| 40.74612808227539|        9.0|  0.5|    0.5|      2.05|         0.0|                  0.3|       12.35|           1|\n",
      "|       1|       1456779600000|        1456780266000|              1|          2.9|-73.98348236083984| 40.76792526245117|         1|                 N|-74.00594329833984|  40.7331657409668|       11.0|  0.5|    0.5|      3.05|         0.0|                  0.3|       15.35|           1|\n",
      "|       2|       1456779600000|        1456781466000|              2|        19.98|-73.78202056884766| 40.64480972290039|         1|                 N|-73.97454071044922|  40.6757698059082|       54.5|  0.5|    0.5|       8.0|         0.0|                  0.3|        63.8|           1|\n",
      "|       2|       1456779600000|        1456779600000|              3|        10.78|-73.86341857910156|40.769813537597656|         1|                 N|-73.96965026855469| 40.75776672363281|       31.5|  0.0|    0.5|      3.78|        5.54|                  0.3|       41.62|           1|\n",
      "|       2|       1456779600000|        1456779600000|              5|        30.43|-73.97174072265625| 40.79218292236328|         3|                 N|-74.17716979980469| 40.69505310058594|       98.0|  0.0|    0.0|       0.0|        15.5|                  0.3|       113.8|           1|\n",
      "|       2|       1456779600000|        1456779600000|              5|         5.92|-74.01719665527344| 40.70538330078125|         1|                 N|-73.97807312011719| 40.75578689575195|       23.5|  1.0|    0.5|      5.06|         0.0|                  0.3|       30.36|           1|\n",
      "|       2|       1456779600000|        1456779600000|              6|         5.72|-73.99458312988281|40.727848052978516|         1|                 N|               0.0|               0.0|       23.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        24.3|           2|\n",
      "|       1|       1456779601000|        1456780564000|              1|          6.2|-73.78877258300781| 40.64775848388672|         1|                 N|-73.82920837402344|40.712345123291016|       20.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        21.8|           3|\n",
      "|       1|       1456779601000|        1456779900000|              1|          0.7|-73.95822143554688| 40.76464080810547|         1|                 N| -73.9678955078125|40.762901306152344|        5.5|  0.5|    0.5|       2.0|         0.0|                  0.3|         8.8|           1|\n",
      "|       2|       1456779601000|        1456781046000|              3|         7.18|-73.98577880859375| 40.74119186401367|         1|                 N|-73.94635009765625| 40.79787826538086|       23.5|  0.5|    0.5|       3.2|         0.0|                  0.3|        28.0|           1|\n",
      "|       2|       1456779601000|        1456779723000|              2|         0.54| -73.9884262084961|    40.76416015625|         1|                 N|-73.99239349365234| 40.75822448730469|        4.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.3|           2|\n",
      "|       1|       1456779602000|        1456780069000|              1|          1.7|-73.96981811523438|40.797428131103516|         1|                 N|-73.94377136230469|40.796199798583984|        8.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.3|           2|\n",
      "|       1|       1456779602000|        1456779785000|              1|          1.1|-73.95380401611328| 40.78812789916992|         1|                 N|-73.97154998779297| 40.79523849487305|        5.5|  0.5|    0.5|       2.2|         0.0|                  0.3|         9.0|           1|\n",
      "|       2|       1456779602000|        1456780172000|              1|          2.1|-73.97608947753906| 40.75217056274414|         1|                 N| -73.9874496459961|40.770782470703125|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|           1|\n",
      "|       2|       1456779602000|        1456781051000|              1|         8.54|-74.00206756591797|40.719120025634766|         1|                 N|-73.95211791992188|40.811241149902344|       27.0|  0.5|    0.5|      5.66|         0.0|                  0.3|       33.96|           1|\n",
      "|       2|       1456779602000|        1456780104000|              1|          2.0|-74.00672912597656|40.730716705322266|         1|                 N|-74.01704406738281| 40.70936584472656|        8.5|  0.5|    0.5|       2.0|         0.0|                  0.3|        11.8|           1|\n",
      "|       1|       1456779603000|        1456780163000|              1|          3.2| -74.0066146850586| 40.71662139892578|         1|                 N|-73.99010467529297| 40.75605010986328|       11.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|           2|\n",
      "|       2|       1456779603000|        1456780114000|              1|         1.59|-73.98226928710938|  40.7706184387207|         1|                 N|-73.96874237060547| 40.75503921508789|        8.0|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|           1|\n",
      "|       2|       1456779603000|        1456781565000|              3|        16.81|-73.79238891601562|  40.6450309753418|         2|                 N|-73.98628997802734| 40.75851821899414|       52.0|  0.0|    0.5|       8.0|        5.54|                  0.3|       66.34|           1|\n",
      "|       1|       1456779604000|        1456779810000|              2|          0.5| -73.9837875366211| 40.73189163208008|         1|                 N|-73.97581481933594|40.728519439697266|        4.5|  0.5|    0.5|      1.15|         0.0|                  0.3|        6.95|           1|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870708b7-d6b8-46e1-926a-9d0214e3e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendorid: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- ratecodeid: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ce3d9-a307-42d4-ac9f-cd3e34b0d6de",
   "metadata": {},
   "source": [
    "## 2. Feature extraction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b607daa8-f48a-45a2-9802-f6195e9ec37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    VectorAssembler,\n",
    "    SQLTransformer,\n",
    "    StandardScaler\n",
    ")\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col, count, when, hour, month, sin, cos, to_timestamp, from_unixtime, lit\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be678629-b393-47ff-bfa2-56f3ebce3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnixMillisToTimestamp(Transformer):\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(UnixMillisToTimestamp, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        return dataset.withColumn(\n",
    "            self.outputCol,\n",
    "            to_timestamp(from_unixtime(col(self.inputCol)/1000))\n",
    "        )\n",
    "\n",
    "    \n",
    "# Custom Transformer to extract hour and month\n",
    "class ExtractHourMonth(Transformer):\n",
    "    def __init__(self, inputCol=None, prefix=\"pickup\"):\n",
    "        super(ExtractHourMonth, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset.withColumn(f\"{self.prefix}_hour\", hour(col(self.inputCol)))\n",
    "        return dataset.withColumn(f\"{self.prefix}_month\", month(col(self.inputCol)))\n",
    "\n",
    "\n",
    "# Custom Transformer for cyclical encoding\n",
    "class CyclicalTimeEncoder(Transformer):\n",
    "    def __init__(self):\n",
    "        super(CyclicalTimeEncoder, self).__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset.withColumn(\"pickup_hour_sin\", sin(2 * math.pi * col(\"pickup_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"pickup_hour_cos\", cos(2 * math.pi * col(\"pickup_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"pickup_month_sin\", sin(2 * math.pi * col(\"pickup_month\") / lit(12)))\n",
    "        dataset = dataset.withColumn(\"pickup_month_cos\", cos(2 * math.pi * col(\"pickup_month\") / lit(12)))\n",
    "        dataset = dataset.withColumn(\"dropoff_hour_sin\", sin(2 * math.pi * col(\"dropoff_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"dropoff_hour_cos\", cos(2 * math.pi * col(\"dropoff_hour\") / lit(24)))\n",
    "        dataset = dataset.withColumn(\"dropoff_month_sin\", sin(2 * math.pi * col(\"dropoff_month\") / lit(12)))\n",
    "        return dataset.withColumn(\"dropoff_month_cos\", cos(2 * math.pi * col(\"dropoff_month\") / lit(12)))\n",
    "\n",
    "\n",
    "class CyclicalGeoEncoder(Transformer):\n",
    "    \"\"\"Encodes latitude and longitude cyclically.\"\"\"\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        # Normalize longitude from [-180,180] to [0,1]\n",
    "        lon_norm = (col(\"pickup_longitude\") + lit(180.0)) / lit(360.0)\n",
    "        lat_norm = (col(\"pickup_latitude\") + lit(90.0)) / lit(180.0)\n",
    "        dataset = dataset.withColumn(\n",
    "            \"pickup_lon_sin\", sin(2 * math.pi * lon_norm)\n",
    "        ).withColumn(\n",
    "            \"pickup_lon_cos\", cos(2 * math.pi * lon_norm)\n",
    "        ).withColumn(\n",
    "            \"pickup_lat_sin\", sin(2 * math.pi * lat_norm)\n",
    "        ).withColumn(\n",
    "            \"pickup_lat_cos\", cos(2 * math.pi * lat_norm)\n",
    "        )\n",
    "        # Repeat for dropoff\n",
    "        lon_norm = (col(\"dropoff_longitude\") + lit(180.0)) / lit(360.0)\n",
    "        lat_norm = (col(\"dropoff_latitude\") + lit(90.0)) / lit(180.0)\n",
    "        return dataset.withColumn(\n",
    "            \"dropoff_lon_sin\", sin(2 * math.pi * lon_norm)\n",
    "        ).withColumn(\n",
    "            \"dropoff_lon_cos\", cos(2 * math.pi * lon_norm)\n",
    "        ).withColumn(\n",
    "            \"dropoff_lat_sin\", sin(2 * math.pi * lat_norm)\n",
    "        ).withColumn(\n",
    "            \"dropoff_lat_cos\", cos(2 * math.pi * lat_norm)\n",
    "        )\n",
    "\n",
    "\n",
    "# Custom Transformer to select features and rename label\n",
    "class SelectAndRename(Transformer):\n",
    "    def _transform(self, dataset):\n",
    "        cols = [\n",
    "            'total_amount', 'vendorid',\n",
    "            'passenger_count', 'trip_distance',\n",
    "            # 'pickup_longitude', 'pickup_latitude',\n",
    "            # 'dropoff_longitude', 'dropoff_latitude',\n",
    "            'pickup_lon_sin', 'pickup_lon_cos', 'pickup_lat_sin', 'pickup_lat_cos',\n",
    "            'dropoff_lon_sin', 'dropoff_lon_cos', 'dropoff_lat_sin', 'dropoff_lat_cos',\n",
    "            'pickup_hour_sin', 'pickup_hour_cos',\n",
    "            'pickup_month_sin', 'pickup_month_cos',\n",
    "            'dropoff_hour_sin', 'dropoff_hour_cos',\n",
    "            'dropoff_month_sin', 'dropoff_month_cos'\n",
    "        ]\n",
    "        dataset = dataset.select(*cols)\n",
    "        return dataset.withColumnRenamed(\"total_amount\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c4592e-bec6-4856-8748-3023a535bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = spark.read.format(\"avro\").table('team11_projectdb.taxi_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aca2631-6a1f-448e-8a55-154f8bb95d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+-------+---------+\n",
      "|          mean_amt|          std_amt|min_amt|  max_amt|\n",
      "+------------------+-----------------+-------+---------+\n",
      "|16.045819673950596|134.3577728869812| -376.3|429562.25|\n",
      "+------------------+-----------------+-------+---------+\n",
      "\n",
      "Total_amount quantiles (50%,75%,90%,95%,99%): [6.8, 7.88, 11.8, 17.76, 28.3, 45.38, 429562.25]\n"
     ]
    }
   ],
   "source": [
    "df_all.selectExpr(\n",
    "    \"mean(total_amount) as mean_amt\",\n",
    "    \"stddev(total_amount) as std_amt\",\n",
    "    \"min(total_amount) as min_amt\",\n",
    "    \"max(total_amount) as max_amt\"\n",
    ").show()\n",
    "\n",
    "total_amount_quantiles = df_all.stat.approxQuantile(\"total_amount\", [0.1, 0.2, 0.5, 0.75, 0.9, 0.95, 0.99], 0.01)\n",
    "print(\"Total_amount quantiles (50%,75%,90%,95%,99%):\", total_amount_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe72fe3-2ca6-42cb-b113-e74789fe3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.filter(col(\"total_amount\") >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400c1b59-d6e9-47f9-badc-326a87b26355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered quantiles: 0.0 429562.25\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Recompute quantiles on cleaned data\n",
    "q1, q99 = df_all.stat.approxQuantile(\"total_amount\", [0.01, 0.99], 0.01)\n",
    "print(\"Filtered quantiles:\", q1, q99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4e52eb-17ba-48e6-80aa-f6847eda5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|total_amount|\n",
      "+------------+\n",
      "|429562.25   |\n",
      "|133131.2    |\n",
      "|126366.58   |\n",
      "|2009.34     |\n",
      "|1463.12     |\n",
      "|1426.8      |\n",
      "|1347.39     |\n",
      "|1273.3      |\n",
      "|1247.3      |\n",
      "|1121.3      |\n",
      "|1000.8      |\n",
      "|989.8       |\n",
      "|983.3       |\n",
      "|981.82      |\n",
      "|934.37      |\n",
      "|902.8       |\n",
      "|901.1       |\n",
      "|900.3       |\n",
      "|892.8       |\n",
      "|852.9       |\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.orderBy(col(\"total_amount\").desc()).select(\"total_amount\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf60b99c-93a8-4953-a5ba-305d5173a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter out outliers outside the 1st and 99th percentiles\n",
    "df_all = df_all.filter(col(\"total_amount\") < 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b9e1c87-7c06-407e-9496-76c399741c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_frac = 0.5\n",
    "# df_sample = df_all.sample(False, sample_frac, seed=42)\n",
    "# train_df, test_df = df_sample.randomSplit([0.2, 0.8], seed=42)\n",
    "# train_df, test_df, _ = df_sample.randomSplit([0.08, 0.2, 0.72], seed=42)\n",
    "\n",
    "# 3. Build preprocessing pipeline with custom transformers\n",
    "preprocessing = Pipeline(stages=[\n",
    "    UnixMillisToTimestamp(inputCol=\"tpep_pickup_datetime\", outputCol=\"pickup_ts\"),\n",
    "    UnixMillisToTimestamp(inputCol=\"tpep_dropoff_datetime\", outputCol=\"dropoff_ts\"),\n",
    "    ExtractHourMonth(inputCol=\"pickup_ts\", prefix=\"pickup\"),\n",
    "    ExtractHourMonth(inputCol=\"dropoff_ts\", prefix=\"dropoff\"),\n",
    "    CyclicalTimeEncoder(),\n",
    "    CyclicalGeoEncoder(),\n",
    "    SelectAndRename(),\n",
    "    VectorAssembler(\n",
    "        inputCols=[\n",
    "            'vendorid',\n",
    "            'passenger_count', 'trip_distance',\n",
    "            'pickup_lon_sin', 'pickup_lon_cos', 'pickup_lat_sin', 'pickup_lat_cos',\n",
    "            'dropoff_lon_sin', 'dropoff_lon_cos', 'dropoff_lat_sin', 'dropoff_lat_cos',\n",
    "            'pickup_hour_sin', 'pickup_hour_cos',\n",
    "            'pickup_month_sin', 'pickup_month_cos',\n",
    "            'dropoff_hour_sin', 'dropoff_hour_cos',\n",
    "            'dropoff_month_sin', 'dropoff_month_cos'\n",
    "        ], outputCol='features_raw'\n",
    "    ),\n",
    "    StandardScaler(inputCol='features_raw',\n",
    "                   outputCol='features',\n",
    "                   withMean=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0035f-da8c-4afb-b5fa-b89d8ec4465d",
   "metadata": {},
   "source": [
    "## 3. Splitting dataset into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0b7a7fc-e7b4-4dd6-8858-93690774fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_frac = 1.0\n",
    "# df_sample = df_all.sample(False, sample_frac, seed=42)\n",
    "\n",
    "train_df, test_df = df_all.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5bc111a2-03aa-4603-a216-870a28dce456",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = preprocessing.fit(train_df)\n",
    "train = temp_model.transform(train_df)\n",
    "test = temp_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8b91cb41-393b-49cf-8d82-325ad6f6e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "# train.select(\"features\", \"label\").coalesce(1)\\\n",
    "#     .write.mode(\"overwrite\").json(\"project/data/train\")\n",
    "# test.select(\"features\", \"label\").coalesce(1)\\\n",
    "#     .write.mode(\"overwrite\").json(\"project/data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2473b-2af2-46c1-8934-faa0b7f71207",
   "metadata": {},
   "source": [
    "## 4. Initial testing of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "027734c2-7fbe-4e28-b71a-cef7e4b6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",\n",
    "                           labelCol=\"label\")\n",
    "model_rf = rf.fit(train)\n",
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4de7183c-589b-4178-9bab-7e00f234f461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Results for RandomForestRegressor ===\n",
      "Training time: 252.23 seconds\n",
      "Evaluation time: 78.13 seconds\n",
      "RMSE: 6.0219\n",
      "R^2: 0.8025\n",
      "MSE: 36.2635\n",
      "MAE: 2.8592\n"
     ]
    }
   ],
   "source": [
    "start_time_test = time.time()\n",
    "predictions = model_rf.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "mse = evaluator.setMetricName(\"mse\").evaluate(predictions)\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "time_test = time.time() - start_time_test\n",
    "\n",
    "print(\"=== Evaluation Results for RandomForestRegressor ===\")\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "print(f\"Evaluation time: {time_test:.2f} seconds\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87fb3770-d7ba-43e8-8b14-88534f2284b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|prediction        |label|\n",
      "+------------------+-----+\n",
      "|9.704670779920333 |5.3  |\n",
      "|9.809457028480228 |8.3  |\n",
      "|10.109131283126016|13.55|\n",
      "|9.650714915315234 |6.3  |\n",
      "|11.04661066767791 |9.3  |\n",
      "|11.17365560341319 |10.3 |\n",
      "|9.704670779920333 |3.8  |\n",
      "|9.456240976962246 |7.5  |\n",
      "|12.118126560211985|15.35|\n",
      "|19.92850204401483 |14.8 |\n",
      "|11.273414656816456|9.8  |\n",
      "|23.382832515995705|25.07|\n",
      "|38.492080336599805|47.89|\n",
      "|9.704670779920333 |7.3  |\n",
      "|16.45193025073419 |13.3 |\n",
      "|16.619592000769323|26.3 |\n",
      "|19.240933145950162|20.15|\n",
      "|12.886050183305429|11.8 |\n",
      "|9.704670779920333 |5.3  |\n",
      "|17.357769717123926|16.8 |\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\") \\\n",
    "    .limit(20) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "238715c6-397c-46f1-81ab-df2dfd0bbbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Results for RandomForestRegressor ===\n",
      "Training time: 230.49 seconds\n",
      "Evaluation time: 69.05 seconds\n",
      "RMSE: 6.2715\n",
      "R^2: 0.7858\n",
      "MSE: 39.3317\n",
      "MAE: 3.0398\n"
     ]
    }
   ],
   "source": [
    "preprocessing = Pipeline(stages=[\n",
    "    UnixMillisToTimestamp(inputCol=\"tpep_pickup_datetime\", outputCol=\"pickup_ts\"),\n",
    "    UnixMillisToTimestamp(inputCol=\"tpep_dropoff_datetime\", outputCol=\"dropoff_ts\"),\n",
    "    ExtractHourMonth(inputCol=\"pickup_ts\", prefix=\"pickup\"),\n",
    "    ExtractHourMonth(inputCol=\"dropoff_ts\", prefix=\"dropoff\"),\n",
    "    CyclicalTimeEncoder(),\n",
    "    CyclicalGeoEncoder(),\n",
    "    SelectAndRename(),\n",
    "    VectorAssembler(\n",
    "        inputCols=[\n",
    "            'vendorid',\n",
    "            'passenger_count', 'trip_distance',\n",
    "            'pickup_longitude', 'pickup_latitude',\n",
    "            'dropoff_longitude', 'dropoff_latitude',\n",
    "            'pickup_hour_sin', 'pickup_hour_cos',\n",
    "            'pickup_month_sin', 'pickup_month_cos',\n",
    "            'dropoff_hour_sin', 'dropoff_hour_cos',\n",
    "            'dropoff_month_sin', 'dropoff_month_cos'\n",
    "        ], outputCol='features_raw'\n",
    "    ),\n",
    "    StandardScaler(inputCol='features_raw',\n",
    "                   outputCol='features',\n",
    "                   withMean=True)\n",
    "])\n",
    "\n",
    "\n",
    "train_df, test_df = df_all.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "temp_model = preprocessing.fit(train_df)\n",
    "train = temp_model.transform(train_df)\n",
    "test = temp_model.transform(test_df)\n",
    "\n",
    "start_time = time.time()\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",\n",
    "                           labelCol=\"label\")\n",
    "model_rf = rf.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "start_time_test = time.time()\n",
    "predictions = model_rf.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "mse = evaluator.setMetricName(\"mse\").evaluate(predictions)\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "time_test = time.time() - start_time_test\n",
    "\n",
    "print(\"=== Evaluation Results for RandomForestRegressor ===\")\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "print(f\"Evaluation time: {time_test:.2f} seconds\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99916a9c-5468-4d29-8a3c-4de0cb4e8b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib64/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-8a10271f950b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   maxDepth=3)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf = GBTRegressor(featuresCol=\"features\",\n",
    "                  labelCol=\"label\",\n",
    "                  maxDepth=3)\n",
    "model_rf = rf.fit(train)\n",
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d18f0-edc9-469a-9912-38387e34a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test = time.time()\n",
    "predictions = model_rf.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.setMetricName(\"rmse\").evaluate(predictions)\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "mse = evaluator.setMetricName(\"mse\").evaluate(predictions)\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "time_test = time.time() - start_time_test\n",
    "\n",
    "print(\"=== Evaluation Results for GBTRegressor ===\")\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "print(f\"Evaluation time: {time_test:.2f} seconds\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ac1f7-4147-4240-bc1e-e1d0d827cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\", \"label\") \\\n",
    "    .limit(50) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694a371-1ff2-4a6f-8c0a-0e2ba0de25d3",
   "metadata": {},
   "source": [
    "## 5. Full training pipeline: baseline models + grid search + saving results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "73c8cf46-3e84-4217-b279-e94fd5c3034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8a9bc174-e945-4a60-ad08-bedb2f0f0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = [\n",
    "    {\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"estimator\": RandomForestRegressor(featuresCol=\"features\",\n",
    "                                           labelCol=\"label\"),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GBT\",\n",
    "        \"estimator\": GBTRegressor(featuresCol=\"features\", labelCol=\"label\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "# Build parameter grids referring to the same estimator instances:\n",
    "models_config[0][\"param_grid\"] = ParamGridBuilder()  \\\n",
    "    .addGrid(models_config[0][\"estimator\"].numTrees, [10, 40])  \\\n",
    "    .addGrid(models_config[0][\"estimator\"].maxDepth, [5, 10])  \\\n",
    "    .build()\n",
    "\n",
    "models_config[1][\"param_grid\"] = ParamGridBuilder()  \\\n",
    "    .addGrid(models_config[1][\"estimator\"].maxDepth, [3, 8])  \\\n",
    "    .addGrid(models_config[1][\"estimator\"].maxBins, [24, 32])  \\\n",
    "    .build()\n",
    "\n",
    "# Add output paths\n",
    "models_config[0].update({\"output_model\": \"model1\",\n",
    "                         \"output_pred\": \"model1_predictions\"})\n",
    "models_config[1].update({\"output_model\": \"model2\",\n",
    "                         \"output_pred\": \"model2_predictions\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a5baf-4230-4c11-a290-7ad5863d0ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running baseline model for: RandomForest ===\n",
      "Baseline training time: 67.48 seconds\n",
      "Baseline RMSE: 6.5116, R²: 0.7722\n",
      "Baseline test time: 11.71 seconds\n",
      "\n",
      "--- Running hyperparameter tuning for: RandomForest ---\n",
      "[{Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
      " {Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
      " {Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 40},\n",
      " {Param(parent='RandomForestRegressor_4e57b2c82f26', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
      "  Param(parent='RandomForestRegressor_4e57b2c82f26', name='numTrees', doc='Number of trees to train (>= 1).'): 40}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in models_config:\n",
    "    print(f\"\\n=== Running baseline model for: {config['name']} ===\")\n",
    "\n",
    "    # Step 1: Train baseline model (no tuning)\n",
    "    base_estimator = config[\"estimator\"]\n",
    "    baseline_start = time.time()\n",
    "    baseline_model = base_estimator.fit(train)\n",
    "    baseline_train_time = time.time() - baseline_start\n",
    "    print(f\"Baseline training time: {baseline_train_time:.2f} seconds\")\n",
    "\n",
    "    baseline_start_test = time.time()\n",
    "    baseline_predictions = baseline_model.transform(test)\n",
    "    baseline_rmse = evaluator.setMetricName(\"rmse\")\\\n",
    "        .evaluate(baseline_predictions)\n",
    "    baseline_r2 = evaluator.setMetricName(\"r2\")\\\n",
    "        .evaluate(baseline_predictions)\n",
    "    baseline_test_time = time.time() - baseline_start_test\n",
    "    print(f\"Baseline RMSE: {baseline_rmse:.4f}, R²: {baseline_r2:.4f}\")\n",
    "    print(f\"Baseline test time: {baseline_test_time:.2f} seconds\")\n",
    "\n",
    "    results.append((\n",
    "        f\"{config['name']}_baseline\",\n",
    "        \"{}\",\n",
    "        baseline_rmse,\n",
    "        baseline_r2,\n",
    "        baseline_train_time,\n",
    "        baseline_test_time\n",
    "    ))\n",
    "\n",
    "    # Save baseline model and predictions\n",
    "    baseline_model.write().overwrite()\\\n",
    "        .save(f\"project/models/{config['output_model']}_baseline\")\n",
    "    baseline_predictions.select(\"label\", \"prediction\") \\\n",
    "        .coalesce(1) \\\n",
    "        .write.mode(\"overwrite\")\\\n",
    "        .csv(f\"project/output/{config['output_pred']}_baseline\", header=True)\n",
    "\n",
    "    # Step 2: Hyperparameter tuning with CrossValidator\n",
    "    print(f\"\\n--- Running hyperparameter tuning for: {config['name']} ---\")\n",
    "    pprint(config[\"param_grid\"])\n",
    "    tuning_start = time.time()\n",
    "\n",
    "    cv = CrossValidator(\n",
    "        estimator=config[\"estimator\"],\n",
    "        estimatorParamMaps=config[\"param_grid\"],\n",
    "        evaluator=evaluator.setMetricName(\"rmse\"),\n",
    "        numFolds=3,\n",
    "        parallelism=4\n",
    "    )\n",
    "    tuned_model = cv.fit(train).bestModel\n",
    "    tuning_train_time = time.time() - tuning_start\n",
    "    print(f\"Tuning completed in {tuning_train_time:.2f} seconds\")\n",
    "\n",
    "    param_map = tuned_model.extractParamMap()\n",
    "    params = {p.name: tuned_model.getOrDefault(p) for p in param_map.keys()}\n",
    "    grid_params = config['param_grid'][0].keys()\n",
    "    relevant_param_names = [gp.name for gp in grid_params]\n",
    "    filtered_params = {k: v for k, v in params.items() if k in relevant_param_names}\n",
    "\n",
    "    # Save tuned model and predictions\n",
    "    tuned_model.write().overwrite()\\\n",
    "        .save(f\"project/models/{config['output_model']}\")\n",
    "    tuning_start_test = time.time()\n",
    "    tuned_predictions = tuned_model.transform(test)\n",
    "    tuned_predictions.select('label', 'prediction') \\\n",
    "        .coalesce(1) \\\n",
    "        .write.mode('overwrite')\\\n",
    "        .csv(f\"project/output/{config['output_pred']}\", header=True)\n",
    "\n",
    "    tuned_rmse = evaluator.setMetricName(\"rmse\").evaluate(tuned_predictions)\n",
    "    tuned_r2 = evaluator.setMetricName(\"r2\").evaluate(tuned_predictions)\n",
    "    print(f\"Tuned RMSE: {tuned_rmse:.4f}, R²: {tuned_r2:.4f}\")\n",
    "    tuning_test_time = time.time() - tuning_start_test\n",
    "    print(f\"Baseline test time: {tuning_test_time:.2f} seconds\")\n",
    "\n",
    "    results.append((\n",
    "        f\"{config['name']}_tuned\",\n",
    "        str(filtered_params),\n",
    "        tuned_rmse,\n",
    "        tuned_r2,\n",
    "        tuning_train_time,\n",
    "        tuning_test_time))\n",
    "# Final summary\n",
    "summary = spark.createDataFrame(results, [\"model\", \"params\", \"rmse\", \"r2\", \"train_time_sec\", \"eval_time_sec\"])\n",
    "summary.show(truncate=False)\n",
    "summary.coalesce(1) \\\n",
    "    .write.mode('overwrite').csv(\"project/output/evaluation\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c035a81a-d315-42c2-954c-27f97a2e4b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'maxDepth': 10, 'numTrees': 40}\n"
     ]
    }
   ],
   "source": [
    "print(filtered_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
